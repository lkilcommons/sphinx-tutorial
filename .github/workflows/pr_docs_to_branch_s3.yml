
# This is a basic workflow to help you get started with Actions
name: Deploy pull-request draft to S3 static site with PR branch name

on:
  # Triggers the workflow on pull request events but only for the "main" branch
  pull_request:
    branches: [ "main" ]
    types: ["opened","synchronize"]

env:
  #These two values determine how bucket will be named
  BUCKET_NAME_STEM: sphinxtutorials3test
  PR_BRANCH_NAME: ${{ github.event.pull_request.head.ref }}
  #These values are used to generate the S3 policy from a template
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  MISSION_IP_BLOCK: ${{ secrets.MISSION_IP_BLOCK }}
  CU_IP_BLOCK1: ${{ secrets.CU_IP_BLOCK1 }}
  CU_IP_BLOCK2: ${{ secrets.CU_IP_BLOCK2 }}
  
jobs:
  deploy:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - name: Set and clean the bucket name
        run: |
          #Define the bucket name
          BUCKET=$BUCKET_NAME_STEM-$PR_BRANCH_NAME
          # Sub out underscores since that's forbidden in S3 names
          BUCKET=${BUCKET/_/-}
          # Add to environment
          echo BUCKET=$BUCKET >> $GITHUB_ENV      
    
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3
      
      - name: Cache conda
        uses: actions/cache@v2
        env:
          # Increase this value to reset cache if etc/example-environment.yml has not changed
          CACHE_NUMBER: 0
        with:
          path: ~/conda_pkgs_dir
          key:
            ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{
            hashFiles('environment.yml') }}

      - name: Create conda environment
        uses: conda-incubator/setup-miniconda@v2
        with:
          activate-environment: sphinxtutorial
          environment-file: environment.yml
          use-mamba: true
          mamba-version: "*"
          python-version: 3.8
          auto-activate-base: false
          
      # Install the package and build docs
      - name:  Run setup.py
        shell: bash -l {0}
        run: |
          python setup.py install
          sphinx-build docs/source docs/html
      
      #Authenticate with AWS
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2
          
      #Create the bucket AWS policy file 
      - name: create-json
        shell: bash
        run: |
          cat > policy.json << EOF
          {
          "Version": "2012-10-17",
          "Statement": [
                  {
                          "Sid": "GithubActionsUserAllow",
                          "Effect": "Allow",
                          "Condition": {
                                  "NotStringLike": {
                                          "aws:userId": [
                                                  "AIDA$AWS_ACCESS_KEY_ID"
                                          ]
                                  }
                          },
                          "Principal": "*",
                          "Action": [
                                  "s3:*"
                          ],
                          "Resource": [
                                  "arn:aws:s3:::$BUCKET",
                                  "arn:aws:s3:::$BUCKET/*"
                          ]
                  },
                  {
                          "Sid": "VPNReadGetObject",
                          "Effect": "Allow",
                          "Condition": {
                                  "IpAddress": {
                                          "aws:SourceIp": [
                                                  "$MISSION_IP_BLOCK",
                                                  "$CU_IP_BLOCK1",
                                                  "$CU_IP_BLOCK2"
                                          ]
                                  }
                          },
                          "Principal": "*",
                          "Action": [
                                  "s3:GetObject"
                          ],
                          "Resource": [
                                  "arn:aws:s3:::$BUCKET/*"
                          ]
                  } 
            ]
          }
          EOF
          
      #Create bucket
      - name:  Create bucket if nessecary
        shell: bash -l {0}
        run: |
          if aws s3api head-bucket --bucket $BUCKET ; then
            echo "$BUCKET already exists! Cleaning it up..."
            aws s3 rm s3://$BUCKET --recursive
          else
            #Create the bucket
            aws s3 mb s3://$BUCKET --region us-west-2
            #Define index and error HTML files which will be landing and 4xx error pages
            aws s3 website s3://$BUCKET \
                    --index-document index.html \
                    --error-document error.html
            #Disable safeguards against accidently or via side-effect enabling public access
            #aws s3api put-public-access-block \
            #        --bucket $BUCKET \
            #        --public-access-block-configuration 'BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false'
            #Explictly allow GET from VPN and Github Actions IAM user via the policy file
            aws s3api put-bucket-policy \
                    --bucket $BUCKET \
                    --policy file://policy.json
            echo "Created S3 bucket $BUCKET"
          fi
      
      # Copy over the website
      - name:  Copy over website
        shell: bash -l {0}
        run: |
          aws s3 cp $GITHUB_WORKSPACE/docs/html s3://$BUCKET --recursive
          
      #Report the built URL
      - uses: mshick/add-pr-comment@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          message: http://${{ env.BUCKET }}.s3-website.us-west-2.amazonaws.com
          allow-repeats: true
